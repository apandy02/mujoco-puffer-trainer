[base]
policy_name = "CleanRLPolicy"
# rnn_name = "Recurrent"  # Assign a value when needed.

[env]

[policy]

[rnn]

# Refer https://github.com/MyoHub/myosuite/blob/main/myosuite/agents/config_mujoco.yaml
[train]
seed = 1
torch_deterministic = true
cpu_offload = false
device = "cuda"
learning_rate = 3e-4
anneal_lr = false
gamma = 0.99
gae_lambda = 0.95
update_epochs = 3
norm_adv = true
clip_coef = 0.2
clip_vloss = true
vf_coef = 0.5
vf_clip_coef = 0.2
max_grad_norm = 0.5
ent_coef = 0.0
# target_kl = None  # Assign a value when needed.

num_envs = 32
num_workers = 16
env_batch_size = 16
zero_copy = false
data_dir = "experiments"
checkpoint_interval = 1000
batch_size = 2048
minibatch_size = 512
bptt_horizon = 16

# Check if the results are the same before compiling
compile = false
compile_mode = "reduce-overhead"

# Extra steps to evaluate the agent after training
eval_timesteps = 320_000

# Train stop criteria
# (1) Max wall time
train_time_budget = 1800  # seconds

# (2) Total timesteps
total_timesteps = 100_000_000


### Sweep related parameters

num_sweeps = 500

[sweep]
method = "bayes"
name = "sweep"

[sweep.metric]
goal = "maximize"
name = "environment/episode_return"

[sweep.parameters.train.parameters.num_envs]
min = 16
max = 64

[sweep.parameters.train.parameters.total_timesteps]
min = 1_000_000
max = 100_000_000

[sweep.parameters.train.parameters.learning_rate]
min = 1e-5
max = 1e-1

[sweep.parameters.train.parameters.gamma]
min = 0.0
max = 1.0

[sweep.parameters.train.parameters.gae_lambda]
min = 0.0
max = 1.0

[sweep.parameters.train.parameters.update_epochs]
min = 1
max = 10

[sweep.parameters.train.parameters.clip_coef]
min = 0.0
max = 1.0

[sweep.parameters.train.parameters.vf_coef]
min = 0.0
max = 10.0

[sweep.parameters.train.parameters.vf_clip_coef]
min = 0.0
max = 1.0

[sweep.parameters.train.parameters.max_grad_norm]
min = 0.0
max = 10.0

[sweep.parameters.train.parameters.ent_coef]
min = 1e-4
max = 0.05

[sweep.parameters.train.parameters.batch_size]
min = 8192
max = 262144

[sweep.parameters.train.parameters.minibatch_size]
min = 256
max = 8192

[sweep.parameters.train.parameters.bptt_horizon]
values = [1, 2, 4, 8, 16, 32]

# NOTE: CARBS results depend a lot on the search center
# We may need separate sets of searach centers for different envs
[carbs.search_center]
num_envs = 32
learning_rate = 0.00176
gamma = 0.9792
gae_lambda = 0.9347
update_epochs = 5
clip_coef = 0.7075
vf_coef = 1.8335
vf_clip_coef = 0.3131
max_grad_norm = 0.7614
ent_coef = 0.00176
batch_size = 32768
minibatch_size = 4096
bptt_horizon = 16