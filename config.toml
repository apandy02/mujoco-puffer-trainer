[base]
policy_name = "CleanRLPolicy"
# rnn_name = "Recurrent"  # Assign a value when needed.

[env]

[policy]

[rnn]

# Refer https://github.com/MyoHub/myosuite/blob/main/myosuite/agents/config_mujoco.yaml
[train]
seed = 1
torch_deterministic = true
cpu_offload = false
device = "cuda"
learning_rate = 3e-4
anneal_lr = false
gamma = 0.99
gae_lambda = 0.95
update_epochs = 3
norm_adv = true
clip_coef = 0.2
clip_vloss = true
vf_coef = 0.5
vf_clip_coef = 0.2
max_grad_norm = 0.5
ent_coef = 0.0
# target_kl = None  # Assign a value when needed.

num_envs = 32
num_workers = 16
env_batch_size = 16
zero_copy = false
data_dir = "experiments"
checkpoint_interval = 1000
batch_size = 2048
minibatch_size = 512
bptt_horizon = 16

# Check if the results are the same before compiling
compile = false
compile_mode = "reduce-overhead"

# Extra steps to evaluate the agent after training
eval_timesteps = 320_000

# Train stop criteria
# (1) Max wall time
train_time_budget = 1800  # seconds

# (2) Total timesteps
total_timesteps = 5_000_000


### Sweep related parameters

num_sweeps = 500

[sweep]
method = "bayes"
name = "sweep"

[sweep.metric]
goal = "maximize"
name = "environment/episode_return"

[sweep.parameters.train.parameters]
# num_envs = { min = 16, max = 64 }

# NOTE: These are differently handled by CARBS
total_timesteps = { min = 1_000_000, max = 100_000_000 }
batch_size = { min = 8192, max = 262144 }
minibatch_size = { min = 256, max = 8192 }
bptt_horizon = { values = [1, 2, 4, 8, 16] }

# These' scales are good for CARBS
learning_rate = { min = 1e-5, max = 1e-1 }
gamma = { min = 0.0, max = 1.0 }
gae_lambda = { min = 0.0, max = 1.0 }
update_epochs = { min = 1, max = 10 }
clip_coef = { min = 0.0, max = 1.0 }
vf_coef = { min = 0.0, max = 10.0 }
vf_clip_coef = { min = 0.0, max = 1.0 }
ent_coef = { min = 1e-4, max = 0.05 }
# max_grad_norm = { min = 0.0, max = 10.0 }

[carbs]
# Special cases, the scale of which are different from above
# Total timesteps is in millions, and batch_size, minibatch_size, bptt_horizon are powers of 2
# These parameters need to be processed before used in training
total_timesteps = { min = 1, max = 10, space = "linear", search_center = 1 }
batch_size = { min = 13, max = 18, space = "linear", search_center = 15 }
minibatch_size = { min = 1, max = 8, space = "linear", search_center = 3 }
bptt_horizon = { min = 1, max = 5, space = "linear", search_center = 3 }

# Others: append min/max from wandb param to carbs param
learning_rate = { space = "log", search_center = 2e-3 }
gamma = { space = "logit", search_center = 0.97 }
gae_lambda = { space = "logit", search_center = 0.90 }
update_epochs = { space = "log", search_center = 5 }
clip_coef = { space = "logit", search_center = 0.5 }
vf_coef = { space = "linear", search_center = 1.0 }
vf_clip_coef = { space = "logit", search_center = 0.5 }
ent_coef = { space = "log", search_center = 0.002 }
# max_grad_norm = { space = "linear", search_center = 0.5 }